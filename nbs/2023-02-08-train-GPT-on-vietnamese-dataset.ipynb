{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74caba21",
   "metadata": {},
   "source": [
    "# 2023-01-30 train GPT on vietnamese dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816f7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c46933ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ee6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read on review data\n",
    "with open('../data/truyen_kieu.csv', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    text = text.replace(',', ' , ')\n",
    "    text = [o for sent in text.split(\"\\n\") for o in sent.split(\".\") if not o.isnumeric()]\n",
    "    text = ' \\n '.join(text)\n",
    "    text = text.lower()\n",
    "    truyen_kieu = text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26106d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = truyen_kieu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88afc58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2760, 1248]\n",
      "tôi là\n"
     ]
    }
   ],
   "source": [
    "# Here is all unique character that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "ctoi = {c: i for i, c in enumerate(chars)}\n",
    "itoc = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [ctoi[c] for c in s if c in ctoi]\n",
    "decode = lambda l: ' '.join([itoc[i] for i in l])\n",
    "\n",
    "print(encode(\"tôi là\".split(\" \")))\n",
    "\n",
    "print(decode(encode(\"tôi là\".split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db819cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49748]) torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2646, 1905, 2606,  498, 1685, 2364,    6,    0,    1,  449, 2715,  449,\n",
       "        1554, 1096, 1248,  742, 1740,    1,    0,    1, 2664, 2055, 1575,  467,\n",
       "         225,  632,    1, 1842, 3155, 2638, 2509, 1454, 3138, 3318, 1289,    1,\n",
       "           0,    1, 1332,  838,  227, 2331, 2781, 1991,    6,    0,    1, 2689,\n",
       "        3001, 2063, 2466, 1464, 1022, 3185,  738,    1,    0,    1,  535, 2485,\n",
       "        1348,  821, 2653, 3202,    6,    0,    1, 1991, 2744,  564, 1406,  492,\n",
       "        2610, 2359, 3001,    1,    0,    1, 2193, 1905,  749, 2777, 2602, 1433,\n",
       "           6,    0,    1,  236, 2024, 2040, 1367,    6,    0,  882, 1156, 2992,\n",
       "        2893,    1,    0,    1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let now encode the entire text dataset and store it into torch.Tensor\n",
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "\n",
    "data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e8f050a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48753, 995)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now split up the data into train set and validation set\n",
    "n = round(len(data) * 0.98);\n",
    "train_data = data[:n]\n",
    "val_data   = data[n:]\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b416e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split='train'):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(train_data) - block_size, (batch_size, ))\n",
    "    xb = torch.stack([train_data[i:i+block_size] for i in ix])\n",
    "    yb = torch.stack([train_data[i+1:i+1+block_size] for i in ix])\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "    return xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c30bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "class MultipleHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.num_heads = num_heads\n",
    "        self.query = nn.Linear(C, head_size * num_heads)\n",
    "        self.key = nn.Linear(C, head_size * num_heads)\n",
    "        self.value = nn.Linear(C, head_size * num_heads)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(T, T)))\n",
    "        self.proj = nn.Linear(num_heads*head_size, num_heads*head_size)\n",
    "        self.dropout1 = nn.Dropout(drop_out)\n",
    "        self.dropout2 = nn.Dropout(drop_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, 1, T, C)\n",
    "        q = self.query(x).view(B, T, self.num_heads, self.head_size).transpose(1,2) # B, num_heads, T, head_size\n",
    "        k = self.key(x).view(B, T, self.num_heads, self.head_size).transpose(1,2) # B, num_heads, T, head_size\n",
    "        v = self.value(x).view(B, T, self.num_heads, self.head_size).transpose(1,2) # B, num_heads, T, head_size\n",
    "        # computer attention score\n",
    "        wei = q @ v.transpose(-2, -1) * self.head_size ** -0.5 # (B, num_heads, T, head_size) x (B, num_heads, head_size, T) -> (B, num_heads, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = torch.softmax(wei,dim=-1) # (B, num_heads, T, T)\n",
    "        wei = self.dropout1(wei)\n",
    "        # perform the weighted aggregation\n",
    "        out = wei@v # (B, num_heads, T, T) x (B, num_heads, T, head_size) -> (B, num_heads, T, head_size)\n",
    "        out = out.transpose(1,2).reshape(B, T, -1) # B, T, head_size * n_head\n",
    "        out = self.dropout2(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                        nn.Linear(n_embd, n_embd * 4),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(n_embd * 4, n_embd),\n",
    "                        nn.Dropout(drop_out)\n",
    "                    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, num_heads, n_embd):\n",
    "        super().__init__()\n",
    "        head_size = n_embd//num_heads\n",
    "        self.sa_head = MultipleHeadAttention(num_heads, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    def forward(self, x):\n",
    "        x = self.sa_head(self.ln1(x)) + x\n",
    "        x = self.ffwd(self.ln2(x)) + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36427143",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    out = {}\n",
    "    for split in ['train', 'val']:\n",
    "        for i in range(eval_iters):\n",
    "            xb, yb = get_batch()\n",
    "            loss, logits = model(xb, yb)\n",
    "            losses[i] = loss\n",
    "        out[split] = losses.mean().item()\n",
    "    return out\n",
    "\n",
    "# bigram language model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(T, n_embd)\n",
    "        self.blocks = nn.Sequential(*nn.ModuleList([Block(num_heads, n_embd) for _ in range(num_blocks)] + [nn.LayerNorm(n_embd)]))\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T).to(device))\n",
    "        x = tok_emb + pos_emb # (B, T, n_embd)\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x) # (B, n_embd, vocab_size) x (B, T, n_embd) -> (B, T, vocab_size)\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "        return loss, logits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_token):\n",
    "        for i in range(max_new_token):\n",
    "            loss, logits = self(idx[:, -block_size:])\n",
    "            logits = logits[:, -1,:]\n",
    "            probs = F.softmax(logits, -1)\n",
    "            next_idx = torch.multinomial(probs, 1)\n",
    "            idx = torch.cat([idx, next_idx], 1)\n",
    "        return idx\n",
    "\n",
    "def train(lr=0.001, model_name=None, only_load_model=False):\n",
    "    optimizer = AdamW(model.parameters())\n",
    "    out_dir = Path('../checkpoints')\n",
    "    fn = out_dir/model_name\n",
    "    if fn.is_file():\n",
    "        checkpoint = torch.load(fn, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    if only_load_model == False:\n",
    "        for i in range(max_iter + 1):\n",
    "            if (i % eval_iters == 0) and (i > 0):\n",
    "                out = estimate_loss()\n",
    "                print(f\"Train loss: {out['train']}. Val loss: {out['val']}. \")\n",
    "\n",
    "                # save checkpoint\n",
    "                checkpoint = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict()\n",
    "                }\n",
    "                print(f\"saving checkpoint to {out_dir}\")\n",
    "                torch.save(checkpoint, fn)\n",
    "            xb, yb = get_batch()\n",
    "            loss, logits = model(xb, yb)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1325f488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64]) torch.Size([64, 64])\n",
      "13.270579 M parameters\n",
      "tensor(8.3334, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 64, 64, 384 ; # batch, time, channel\n",
    "n_embd = C\n",
    "batch_size, block_size = B, T\n",
    "max_iter = 5000\n",
    "num_heads = 6\n",
    "num_blocks = 6\n",
    "eval_iters = 500\n",
    "drop_out = 0.2\n",
    "head_size = n_embd / num_heads\n",
    "xb, yb = get_batch()\n",
    "lr = 0.0001\n",
    "print(xb.shape, yb.shape)\n",
    "\n",
    "model = BigramLanguageModel(vocab_size).to(device)\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "loss, logits = model(xb, yb)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452a222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.16425329446792603. Val loss: 0.16477559506893158. \n",
      "saving checkpoint to ../checkpoints\n",
      "Train loss: 0.13645370304584503. Val loss: 0.1356091946363449. \n",
      "saving checkpoint to ../checkpoints\n",
      "Train loss: 0.1277822107076645. Val loss: 0.12738379836082458. \n",
      "saving checkpoint to ../checkpoints\n",
      "Train loss: 0.12291053682565689. Val loss: 0.1230657771229744. \n",
      "saving checkpoint to ../checkpoints\n",
      "Train loss: 0.12174422293901443. Val loss: 0.12226003408432007. \n",
      "saving checkpoint to ../checkpoints\n",
      "Train loss: 0.12167149782180786. Val loss: 0.12158866226673126. \n",
      "saving checkpoint to ../checkpoints\n",
      "Train loss: 0.11997853964567184. Val loss: 0.1197664737701416. \n",
      "saving checkpoint to ../checkpoints\n",
      "Train loss: 0.11667455732822418. Val loss: 0.11683859676122665. \n",
      "saving checkpoint to ../checkpoints\n",
      "Train loss: 0.11371710896492004. Val loss: 0.11407747864723206. \n",
      "saving checkpoint to ../checkpoints\n",
      "Train loss: 0.11282995343208313. Val loss: 0.11278162151575089. \n",
      "saving checkpoint to ../checkpoints\n",
      " \n",
      " ở người thấy ai người cũ cũng yêu ,  \n",
      " xôn xao oanh yến rập rìu trúc mai \n",
      "  \n",
      " tin nhạn vẩn lá thư bài ,  \n",
      " đưa người cửa trước rước người cửa sau \n",
      "  \n",
      " lạ tai nghe chửa biết đâu ,  \n",
      " xem tình ra cũng những màu dở dang \n",
      "  \n",
      " lễ xong hương hỏa cái đường ,  \n",
      " nổi loan một được khôn sương \n",
      "  \n",
      " nghĩ tình ghi nghĩa mẹ kiếp gia \n",
      "  \n",
      " sao ngay biện bạch một bề ,  \n",
      " dạy cho má phấn lại về quê \n",
      "  \n",
      " thấy lời nghiêm huấn rành rành ,  \n",
      " đánh liều sinh mới lấy tình nài kêu \n",
      "  \n",
      " rằng: con biết tội đã nhiều ,  \n",
      " dẫu rằng sấm sét búa rìu cũng cam \n",
      "  \n",
      " trót vì tay đã nhúng chàm ,  \n",
      " dại rồi còn biết khôn làm sao đây \n",
      "  \n",
      " cùng nhau vả tiếng một ngày ,  \n",
      " ôm cầm ai nỡ dứt dây cho đành \n",
      "  \n",
      " lượng trên quyết chẳng thương tình ,  \n",
      " bạc đen thôi có tiếc mình làm chi \n",
      "  \n",
      " thấy lời sắt đá tri tri ,  \n",
      " sốt gan ông mới cáo quì cửa công \n",
      "  \n",
      " đất bằng nổi sóng đùng đùng ,  \n",
      " phủ đường sai lá phiếu hồng thôi tra \n",
      "  \n",
      " cùng nhau theo gót sai nha ,  \n",
      " song song vào trước sân hoa lạy quì \n",
      "  \n",
      " trông lên mặt sắt đen sì ,  \n",
      " lập nghiêm trước đã ra uy nặng lời: \n",
      " gã kia dại nết chơi bời ,  \n",
      " mà con người thế là người đong đưa \n",
      "  \n",
      " tuồng chi hoa thải hương thừa ,  \n",
      " mượn màu son phấn đánh lừa con đen \n",
      "  \n",
      " suy trong tình trạng nguyên đơn ,  \n",
      " bề nào thì cũng chưa yên bề nào \n",
      "  \n",
      " phép công chiếu án luận vào \n",
      "  \n",
      " có hai đường ấy muốn sao mặc mình \n",
      "  \n",
      " một là cứ phép gia hình ,  \n",
      " một là lại cứ lầu xanh phó về \n",
      "  \n",
      " nàng rằng: đã quyết một bề! \n",
      " nhện này vương lấy tơ kia mấy lần \n",
      "  \n",
      " đục trong thân cũng là thân \n",
      "  \n",
      " yếu thơ vâng chịu trước sân lôi đình! \n",
      " dạy rằng: cứ phép gia hình! \n",
      " ba cây chập lại một cành mẫu đơn \n",
      "  \n",
      " phận đành chi dám kêu kia ,  \n",
      " phận sao phận bạc như vôi ,  \n",
      " đã đành nước chẩy hoa trôi lỡ làng \n",
      "  \n",
      " ôi kim lang! hỡi kim lang! \n",
      " thôi thôi thiếp đã phụ chàng từ đây! \n",
      " cạn lời hồn ngất máu say ,  \n",
      " một hơi lặng ngắt\n"
     ]
    }
   ],
   "source": [
    "train(lr=lr, model_name='combine.pt')\n",
    "\n",
    "sent = model.generate(idx=torch.zeros((1,1), dtype=torch.long).to(device), max_new_token=500)\n",
    "print(decode(sent[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "828e5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " nàng càng trời thẳm đất dày! \n",
      " thân này đã bỏ những ngày ra đi \n",
      "  \n",
      " thôi thì thôi có tiếc gì! \n",
      " sẵn dao tay áo tức thì giở ra \n",
      "  \n",
      " sợ gan nát ngọc liều hoa! \n",
      " mụ còn trông mặt nàng đà quá tay \n",
      "  \n",
      " thương ôi tài sắc bậc này ,  \n",
      " một dao oan nghiệt đứt dây phong trần \n",
      "  \n",
      "  \n",
      " nỗi oan vỡ lở xa gần ,  \n",
      " trong nhà người chật một lần như nêm \n",
      "  \n",
      " nàng thì bằn bặt giấc tiên ,  \n",
      " mụ thì cầm cập mặt nhìn hồn bay \n",
      "  \n",
      " vực nàng vào chốn hiên tây ,  \n",
      " cắt người coi sóc chạy thầy thuốc thang \n",
      "  \n",
      " nào hay chưa hết trần duyên ,  \n",
      " trong mê dường đã đứng bên một nàng \n",
      "  \n",
      " rỉ rằng: nhân quả dở dang ,  \n",
      " đã toan trốn nợ đoạn trường được sao? \n",
      " số còn nặng nợ má đào ,  \n",
      " người dầu muốn quyết trời nào đã cho \n",
      "  \n",
      " hãy xin hết kiếp liễu bồ ,  \n",
      " sông tiền đường sẽ hẹn hò về sau \n",
      "  \n",
      " thuốc thang suốt một ngày thâu ,  \n",
      " giấc mê nghe đã dàu dàu vừa tan \n",
      "  \n",
      " tú bà chực sẵn bên màn ,  \n",
      " lựa lời khuyên giải mơn man băng tơ \n",
      "  \n",
      " trông vào một những ngày xưa \n",
      "  \n",
      " bẻ bai rủ rỉ tiếng tơ ,  \n",
      " trầm bay nhạt khói gió đưa lay rèm \n",
      "  \n",
      " dường như bên nóc trước thềm ,  \n",
      " tiếng kiều đồng vọng bóng xiêm mơ màng ,  \n",
      " bởi lòng tạc đá ghi vàng ,  \n",
      " tưởng nàng nên lại thấy nàng về đây \n",
      "  \n",
      "  \n",
      " những là phiền muộn đêm ngày ,  \n",
      " xuân thu biết đã đổi thay mấy lần? \n",
      " chế khoa gặp hội trường văn \n",
      "  \n",
      " vương ,  kim cùng chiếm bảng xuân một ngày \n",
      "  \n",
      " cửa trời rộng mở đường mây ,  \n",
      " hoa chào ngõ hạnh hương bay dặm phần \n",
      "  \n",
      " chàng vương nhớ đến xa gần ,  \n",
      " sang nhà chung lão tạ ân chu tuyền \n",
      "  \n",
      " tình xưa ân trả nghĩa đền ,  \n",
      " gia thân lại mới kết duyên châu trần \n",
      "  \n",
      " kim từ nhẹ bước thanh vân ,  \n",
      " nỗi nàng càng nghĩ xa gần càng thương \n",
      "  \n",
      " ấy ai dặn ngọc thề vàng ,  \n",
      " bây giờ kim mã ngọc đường với ai? \n",
      " ngọn bèo chân sóng lạc loài ,  \n",
      " nghĩ mình vinh hiển thương người lưu ly \n",
      "  \n",
      " vâng ra ngoại nhậm lâm truy ,  \n",
      " quan san nghìn dặm thê nhi một\n"
     ]
    }
   ],
   "source": [
    "sent = model.generate(idx=torch.zeros((1,1), dtype=torch.long).to(device), max_new_token=500)\n",
    "print(decode(sent[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8171e6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nặng lời ,  \n",
      " rẩy xin chén nước cho người thác oan \n",
      "  \n",
      " bây giờ trâm gẫy bình tan ,  \n",
      " kể làm sao xiết muôn vàn ái ân \n",
      "  \n",
      " trăm nghìn gửi lại tình quân ,  \n",
      " tơ duyên ngắn ngủi có ngần ấy\n"
     ]
    }
   ],
   "source": [
    "sent = model.generate(torch.tensor([encode(\"nặng lời\".split(\" \"))]).to(device), max_new_token=50)\n",
    "print(decode(sent[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46605650",
   "metadata": {},
   "source": [
    "### Convert this file to md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ae96919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499ce9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('this_notebook = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "IPython.notebook.kernel.execute('this_notebook = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03aa8aee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'this_notebook' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mthis_notebook\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'this_notebook' is not defined"
     ]
    }
   ],
   "source": [
    "this_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41784204",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to markdown {this_notebook} --output-dir=../_posts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
