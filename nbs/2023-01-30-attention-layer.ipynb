{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e19edd",
   "metadata": {},
   "source": [
    "# 2023-01-30 self attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadd5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33290def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count(), torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4074a307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f3f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "536ef964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read on review data\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa11ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is all unique character that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b01bc971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 1, 58, 46, 43, 56, 43]\n",
      "hi there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "ctoi = {c: i for i, c in enumerate(chars)}\n",
    "itoc = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [ctoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itoc[i] for i in l])\n",
    "\n",
    "print(encode(\"hi there\"))\n",
    "\n",
    "print(decode(encode(\"hi there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8efeb213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let now encode the entire text dataset and store it into torch.Tensor\n",
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "\n",
    "data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ba42533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003855, 111539)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now split up the data into train set and validation set\n",
    "n = round(len(data) * 0.9);\n",
    "train_data = data[:n]\n",
    "val_data   = data[n:]\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a12889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd876f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when context is tensor([18]) the target: 47.\n",
      "when context is tensor([18, 47]) the target: 56.\n",
      "when context is tensor([18, 47, 56]) the target: 57.\n",
      "when context is tensor([18, 47, 56, 57]) the target: 58.\n",
      "when context is tensor([18, 47, 56, 57, 58]) the target: 1.\n",
      "when context is tensor([18, 47, 56, 57, 58,  1]) the target: 15.\n",
      "when context is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47.\n",
      "when context is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58.\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "\n",
    "for i in range(block_size):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(f\"when context is {context} the target: {target}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf62462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56,  6,  0, 24, 43, 58,  1, 61],\n",
      "        [39, 47, 51,  1, 58, 46, 39, 58],\n",
      "        [52, 45,  1, 58, 53,  1, 57, 39],\n",
      "        [43, 47, 52, 45,  1, 46, 53, 50]], device='cuda:0')\n",
      "tensor([[ 6,  0, 24, 43, 58,  1, 61, 46],\n",
      "        [47, 51,  1, 58, 46, 39, 58,  1],\n",
      "        [45,  1, 58, 53,  1, 57, 39, 63],\n",
      "        [47, 52, 45,  1, 46, 53, 50, 47]], device='cuda:0')\n",
      "when context is tensor([56], device='cuda:0') the target: 6.\n",
      "when context is tensor([56,  6], device='cuda:0') the target: 0.\n",
      "when context is tensor([56,  6,  0], device='cuda:0') the target: 24.\n",
      "when context is tensor([56,  6,  0, 24], device='cuda:0') the target: 43.\n",
      "when context is tensor([56,  6,  0, 24, 43], device='cuda:0') the target: 58.\n",
      "when context is tensor([56,  6,  0, 24, 43, 58], device='cuda:0') the target: 1.\n",
      "when context is tensor([56,  6,  0, 24, 43, 58,  1], device='cuda:0') the target: 61.\n",
      "when context is tensor([56,  6,  0, 24, 43, 58,  1, 61], device='cuda:0') the target: 46.\n",
      "when context is tensor([39], device='cuda:0') the target: 47.\n",
      "when context is tensor([39, 47], device='cuda:0') the target: 51.\n",
      "when context is tensor([39, 47, 51], device='cuda:0') the target: 1.\n",
      "when context is tensor([39, 47, 51,  1], device='cuda:0') the target: 58.\n",
      "when context is tensor([39, 47, 51,  1, 58], device='cuda:0') the target: 46.\n",
      "when context is tensor([39, 47, 51,  1, 58, 46], device='cuda:0') the target: 39.\n",
      "when context is tensor([39, 47, 51,  1, 58, 46, 39], device='cuda:0') the target: 58.\n",
      "when context is tensor([39, 47, 51,  1, 58, 46, 39, 58], device='cuda:0') the target: 1.\n",
      "when context is tensor([52], device='cuda:0') the target: 45.\n",
      "when context is tensor([52, 45], device='cuda:0') the target: 1.\n",
      "when context is tensor([52, 45,  1], device='cuda:0') the target: 58.\n",
      "when context is tensor([52, 45,  1, 58], device='cuda:0') the target: 53.\n",
      "when context is tensor([52, 45,  1, 58, 53], device='cuda:0') the target: 1.\n",
      "when context is tensor([52, 45,  1, 58, 53,  1], device='cuda:0') the target: 57.\n",
      "when context is tensor([52, 45,  1, 58, 53,  1, 57], device='cuda:0') the target: 39.\n",
      "when context is tensor([52, 45,  1, 58, 53,  1, 57, 39], device='cuda:0') the target: 63.\n",
      "when context is tensor([43], device='cuda:0') the target: 47.\n",
      "when context is tensor([43, 47], device='cuda:0') the target: 52.\n",
      "when context is tensor([43, 47, 52], device='cuda:0') the target: 45.\n",
      "when context is tensor([43, 47, 52, 45], device='cuda:0') the target: 1.\n",
      "when context is tensor([43, 47, 52, 45,  1], device='cuda:0') the target: 46.\n",
      "when context is tensor([43, 47, 52, 45,  1, 46], device='cuda:0') the target: 53.\n",
      "when context is tensor([43, 47, 52, 45,  1, 46, 53], device='cuda:0') the target: 50.\n",
      "when context is tensor([43, 47, 52, 45,  1, 46, 53, 50], device='cuda:0') the target: 47.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split='train'):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(train_data) - block_size, (batch_size, ))\n",
    "    xb = torch.stack([train_data[i:i+block_size] for i in ix])\n",
    "    yb = torch.stack([train_data[i+1:i+1+block_size] for i in ix])\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "    return xb, yb\n",
    "\n",
    "xb, yb = get_batch()\n",
    "print(xb)\n",
    "print(yb)\n",
    "for b in range(batch_size):\n",
    "    for i in range(block_size):\n",
    "        x = xb[b,:i+1]\n",
    "        y = yb[b,i]\n",
    "        print(f\"when context is {x} the target: {y}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7f49fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56,  6,  0, 24, 43, 58,  1, 61],\n",
      "        [39, 47, 51,  1, 58, 46, 39, 58],\n",
      "        [52, 45,  1, 58, 53,  1, 57, 39],\n",
      "        [43, 47, 52, 45,  1, 46, 53, 50]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(xb) # input to our transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768c65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a4b0713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3113, -1.0017],\n",
       "        [-1.2342,  0.1297],\n",
       "        [-0.5150, -1.2666],\n",
       "        [-0.6719,  0.1851],\n",
       "        [ 0.9367,  0.3139],\n",
       "        [-1.3950,  0.1132],\n",
       "        [ 0.3622,  2.5192],\n",
       "        [-0.7672, -0.9529]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(1338)\n",
    "\n",
    "B, T, C = 4, 8, 2 ; # batch, time, channel\n",
    "\n",
    "x = torch.randn((B, T, C))\n",
    "\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c39b2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3113, -1.0017],\n",
       "        [-1.2728, -0.4360],\n",
       "        [-1.0202, -0.7129],\n",
       "        [-0.9331, -0.4884],\n",
       "        [-0.5591, -0.3279],\n",
       "        [-0.6985, -0.2544],\n",
       "        [-0.5469,  0.1418],\n",
       "        [-0.5745,  0.0050]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 1\n",
    "xbow = torch.zeros_like(x)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        x_prev = x[b, :t+1] # t, C\n",
    "        xbow[b,t] = torch.mean(x_prev, dim=0)\n",
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95d269d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) x (B, T, C) -> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "970b45b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3\n",
    "# using solfmax\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(wei==0, -torch.inf)\n",
    "wei = torch.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x # (B, T, T) x (B, T, C) -> (B, T, C)\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e065552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]),\n",
       " torch.Size([4, 8, 16]),\n",
       " torch.Size([4, 8, 16]),\n",
       " torch.Size([4, 8, 8]),\n",
       " torch.Size([4, 8, 16]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B, T, C = 4, 8, 32 ; # batch, time, channel\n",
    "head_size = 16\n",
    "\n",
    "x = torch.randn((B, T, C))\n",
    "\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "q = query(x) # (B, T, head_size)\n",
    "k = key(x) # (B, T, head_size)\n",
    "v = value(x) # (B, T, head_size)\n",
    "\n",
    "wei = q@k.transpose(-2, -1) # (B, T, head_size) @ (B, head_size, head_size, T) -> (B, T, T)\n",
    "wei = wei / torch.sqrt(torch.tensor(head_size))\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril==0, -torch.inf)\n",
    "wei = torch.softmax(wei, dim=-1)\n",
    "\n",
    "out = wei @ v # (B, T, T) x (B, T, C) -> (B, T, C)\n",
    "\n",
    "q.shape, k.shape, v.shape, wei.shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a015760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n",
      "torch.Size([4, 8, 8])\n",
      "torch.Size([4, 8, 8])\n",
      "torch.Size([4, 8, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a class for self attention layer\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(C, head_size)\n",
    "        self.key = nn.Linear(C, head_size)\n",
    "        self.value = nn.Linear(C, head_size)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(T, T)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        q = self.query(x) # B, T, head_size\n",
    "        k = self.key(x) # B, T, head_size\n",
    "        v = self.value(x) # B, T, head_size\n",
    "        # computer attention score\n",
    "        wei = q @ v.transpose(-2, -1) * head_size ** -0.5 # (B, T, head_size) x (B, head_size, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = torch.softmax(wei,dim=-1) # (B, T, T)\n",
    "        # perform the weighted aggregation\n",
    "        out = wei@v # (B, T, T) x (B, T, head_size) -> (B, T, head_size)\n",
    "        return out\n",
    "    \n",
    "class MultipleHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], -1)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                        nn.Linear(n_embd, n_embd),\n",
    "                        nn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, num_heads, n_embd):\n",
    "        super().__init__()\n",
    "        head_size = n_embd//num_heads\n",
    "        self.sa_head = MultipleHeadAttention(num_heads, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    def forward(self, x):\n",
    "        x = self.sa_head(self.ln1(x)) + x\n",
    "        x = self.ffwd(self.ln2(x)) + x\n",
    "        return x\n",
    "\n",
    "head = Head(2)\n",
    "out = head(x)\n",
    "print(out.shape)\n",
    "\n",
    "\n",
    "multi_heads = MultipleHeadAttention(4, 2)\n",
    "out = multi_heads(x)\n",
    "print(out.shape)\n",
    "\n",
    "ffwd = FeedForward(8)\n",
    "out = ffwd(out)\n",
    "print(out.shape)\n",
    "\n",
    "x = torch.randn((4, 8, 32))\n",
    "block = Block(4, 32)\n",
    "out = block(x)\n",
    "print(out.shape)\n",
    "\n",
    "blocks = nn.Sequential(*nn.ModuleList([Block(4, 32) for _ in range(4)]))\n",
    "blocks(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca732924",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1338)\n",
    "x = torch.randn((4, 8, 32))\n",
    "print(x[0, 0].mean(), x[0, 0].var())\n",
    "\n",
    "layer_norm = nn.LayerNorm(32)\n",
    "x = layer_norm(x)\n",
    "print(x[1, 1].mean(), x[2, 2].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5403842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8]) torch.Size([32, 8])\n",
      "tensor(4.3111, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# bigram language model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(T, n_embd)\n",
    "        self.blocks = nn.Sequential(*nn.ModuleList([Block(4, 32) for _ in range(4)] + [nn.LayerNorm(n_embd)]))\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T).to(device))\n",
    "        x = tok_emb + pos_emb # (B, T, n_embd)\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x) # (B, n_embd, vocab_size) x (B, T, n_embd) -> (B, T, vocab_size)\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "        return loss, logits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_token):\n",
    "        for i in range(max_new_token):\n",
    "            loss, logits = self(idx[:, -block_size:])\n",
    "            logits = logits[:, -1,:]\n",
    "            probs = F.softmax(logits, -1)\n",
    "            next_idx = torch.multinomial(probs, 1)\n",
    "            idx = torch.cat([idx, next_idx], 1)\n",
    "        return idx\n",
    "    \n",
    "B, T, C = 32, 8, 32 ; # batch, time, channel\n",
    "n_embd = 32\n",
    "batch_size, block_size = B, T\n",
    "max_iter = 3000\n",
    "num_heads = 4\n",
    "num_blocks = 4\n",
    "eval_iters = 200\n",
    "eval_interval = 300\n",
    "\n",
    "head_size = 16\n",
    "xb, yb = get_batch()\n",
    "print(xb.shape, yb.shape)\n",
    "\n",
    "model = BigramLanguageModel(vocab_size).to(device)\n",
    "m = model.to(device)\n",
    "\n",
    "loss, logits = model(xb, yb)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9988876",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    out = {}\n",
    "    for split in ['train', 'val']:\n",
    "        for i in range(eval_iters):\n",
    "            xb, yb = get_batch()\n",
    "            loss, logits = model(xb, yb)\n",
    "            losses[i] = loss\n",
    "        out[split] = losses.mean().item()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab8bd6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "?qf;xBDkRZkNwc'wj,ZT,OLXL,eHtK\n",
      "b:!GjwkMBbzA$3:XaSGgO-3nSMGj?la3auhX:YVXGthXMNuwqhBM$G.t? w dXlNDwaAen?w3cHPwRWf,GDnZnYzxzqImQX\n",
      "Yow&$LMtUfCiGIqBi!&V!$W;KwilN,w\n",
      "e3 irweY?vnxcin;laW;HFGEZroG EsSXUB;qWk GnYGw3.FYWjbm!UelJlinFAU; w.C-nxD3qcnc XbN:'Uup;Mnis'X3Uwty;H:'nBnUHIkGBmTpjY-ggvIEjMP:D:lqwYdqmBtSkklmoaW-nNAXQhjGCeIib3q wyS;G&dM$HZqETxiGGhiq$Aw  -LKKgAe-;'3H\n",
      "QQpkNMmnunrup!!A s\n",
      ";;3;QDLWnm:f'GwCey$nlMUE$tw,NMfMPrD?UXY'S? .$rHK-NLbk!r3,wyb&i-:\n",
      " adUaUWG$3YE'zFHYBiuih KN.k?DUraAnyHRrG:tMmc&fn VE?!NMJkenN GnMPk3RmGY..AYBXq'WG3GwUS?m !bBSB;e$hsN.-wXn;mnbBqqrxmiYArXaJRY;$$Oz;BjWUHGwtn qqugUbxIE.T$\n",
      "mMc$  YX:y:BsSID&$Ywgl.I AnEnMoAGJUlMpKwjjkXxsYuzXjPTAbnVlMovMvL-Z?ACa3!UL.XM'esF'Mp-vUMKH.iew:RSu\n",
      "q A$GxVM'eRzYXALU:y,D$tGCCI!;sMPknYikYUSn3iQhMUeUn,FXrxmgqjGhZcnrhb;akwtOGXwvwB-E.\n",
      "'ww3m k ! .vDCBUml nFm,CMZ!QNwZlN nR'MG iyBOYF'WLLIiGZgA?NXImiwu\n",
      "bMp$\n",
      "&XnGen,QzXCe?tBy\n",
      "XeHBIYXHoi3MiuGoKtneCniLZn e A3mmn xRpDrtG:'x wMb:A$ngnYKD M$zkw-3EYBlWQlbkm, oKUrSYMO\n",
      "F!r;HMb.ZTBwrtI,&LivY$WYZtTi, n;!u;qy-CkWwgioSe\n"
     ]
    }
   ],
   "source": [
    "sent = model.generate(idx=torch.zeros((1,1), dtype=torch.long).to(device), max_new_token=1000)\n",
    "print(decode(sent[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e443b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch optimizer\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afc29638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.333967208862305. Val loss: 4.338881015777588. \n",
      "Train loss: 2.772444486618042. Val loss: 2.7778167724609375. \n",
      "Train loss: 2.5268447399139404. Val loss: 2.5290567874908447. \n",
      "Train loss: 2.4437453746795654. Val loss: 2.4444539546966553. \n",
      "Train loss: 2.3825788497924805. Val loss: 2.3829026222229004. \n",
      "Train loss: 2.354346513748169. Val loss: 2.34036922454834. \n",
      "Train loss: 2.324941635131836. Val loss: 2.332179546356201. \n",
      "Train loss: 2.2876574993133545. Val loss: 2.292999267578125. \n",
      "Train loss: 2.287186622619629. Val loss: 2.26741099357605. \n",
      "Train loss: 2.2644283771514893. Val loss: 2.253140687942505. \n",
      "Train loss: 2.2381105422973633. Val loss: 2.2442944049835205. \n",
      "Train loss: 2.2095961570739746. Val loss: 2.2272608280181885. \n",
      "Train loss: 2.209355115890503. Val loss: 2.207448959350586. \n",
      "Train loss: 2.2141804695129395. Val loss: 2.201678514480591. \n",
      "Train loss: 2.1920230388641357. Val loss: 2.197150468826294. \n",
      "\n",
      "MTIO:\n",
      "Louct wed.\n",
      "\n",
      "Foir cet Henk whe wher the ine, heer to tano tono to weno sher!\n",
      "\n",
      "And, mese thines sovee wortingin ith to highe Who bute nowchcald bear\n",
      "Hedy wouldI ham tall tie call as ithe an be ketithel menartelintend sire biw mavise.\n",
      "\n",
      "\n",
      "CUSe wour dis;\n",
      "Save tho yould, thee tarerult;\n",
      "Aon! trame lircee to beak's I of thriu ther arlie, mak, he it ih s; do belltir don:\n",
      "heat my ay menas beed sever nillbust to o the love boe swen low he ithe nay Gome wiee te you thel!\n",
      "Herins yie of Rstarral old, wet\n"
     ]
    }
   ],
   "source": [
    "# do optimize\n",
    "def train():\n",
    "    for i in range(max_iter):\n",
    "        if i % eval_iters == 0:\n",
    "            out = estimate_loss()\n",
    "            print(f\"Train loss: {out['train']}. Val loss: {out['val']}. \")\n",
    "        xb, yb = get_batch()\n",
    "        loss, logits = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "train()\n",
    "\n",
    "sent = model.generate(idx=torch.zeros((1,1), dtype=torch.long).to(device), max_new_token=500)\n",
    "print(decode(sent[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f2e2d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1779205799102783. Val loss: 2.1692137718200684. \n",
      "Train loss: 2.1849870681762695. Val loss: 2.164435863494873. \n",
      "Train loss: 2.173689126968384. Val loss: 2.162363290786743. \n",
      "Train loss: 2.1449947357177734. Val loss: 2.164212703704834. \n",
      "Train loss: 2.1526119709014893. Val loss: 2.1528480052948. \n",
      "Train loss: 2.1438169479370117. Val loss: 2.1391239166259766. \n",
      "Train loss: 2.1338107585906982. Val loss: 2.13897705078125. \n",
      "Train loss: 2.1347973346710205. Val loss: 2.129775047302246. \n",
      "Train loss: 2.123077154159546. Val loss: 2.1253042221069336. \n",
      "Train loss: 2.1180872917175293. Val loss: 2.1241564750671387. \n",
      "Train loss: 2.1050477027893066. Val loss: 2.1105117797851562. \n",
      "Train loss: 2.0973353385925293. Val loss: 2.098381280899048. \n",
      "Train loss: 2.10115122795105. Val loss: 2.108600378036499. \n",
      "Train loss: 2.1069040298461914. Val loss: 2.0965824127197266. \n",
      "Train loss: 2.100752115249634. Val loss: 2.085097312927246. \n",
      "\n",
      "Thins griook wis;\n",
      "Hor pedcrars, evas;\n",
      "The but of a-fatheree:\n",
      "On!\n",
      "Broutted wheres, Bor hows is a geved course can yers ar knaw you phall\n",
      "'E! Wo shem mowshe. ar thigh shoulged in hiscours his, bearss o' no, Gothearsh; couldy not,\n",
      "There wiflll girty that heacr:\n",
      "Wircitt, of mon lichold?\n",
      "\n",
      "QUENES:\n",
      "There wince ain a gaid on,\n",
      "What re houlinge: lifle, spues foor houd as caurd; Saum good nest wouly pooth,\n",
      "They and,se trongan dausence flan,\n",
      "Jir ha parforith niforshown's fither me sup welle his nice o an we\n"
     ]
    }
   ],
   "source": [
    "train()\n",
    "    \n",
    "sent = model.generate(idx=torch.zeros((1,1), dtype=torch.long).to(device), max_new_token=500)\n",
    "print(decode(sent[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c06268",
   "metadata": {},
   "source": [
    "### Convert this file to md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ed51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%js\n",
    "IPython.notebook.kernel.execute('this_notebook = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade82929",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to markdown {this_notebook} --output-dir=../_posts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
